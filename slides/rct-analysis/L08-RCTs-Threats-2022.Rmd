---
title: "<b> Threats and Limitations of RCTs </b>"
subtitle: "<em> Impact evaluation: Effects of social policies on health </em>"  
author: "8 Feb 2022"
institute: "Sam Harper & Arijit Nandi"
date: "  "
output:
  xaringan::moon_reader:
    lib_dir: libs
    seal: true
    css: [xaringan-themer.css, style.css]
    nature:
      beforeInit: "macros.js"
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
      titleSlideClass: [middle, left]
header-includes:
- \usepackage{tikzsymbols}
- \usetikzlibrary{arrows,shapes,backgrounds}
- \usepackage{wasysym}
---
```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
library(here)
library(tidyverse)
library(broom)
library(broom.mixed)
library(pixiedust)
library(here)
library(DiagrammeR)
library(kableExtra)
library(xaringan)
library(leaflet)
library(ggplot2)
library(ggeffects)
library(lme4)
library(emojifont)
library(RefManageR)
xfun::pkg_load2(c('tikzDevice', 'magick', 'pdftools'))
source(here("data", "helper.R"))
BibOptions(check.entries = FALSE, bib.style = "authoryear", style = "markdown",
           dashed = TRUE, max.names=1)
bib <- ReadBib(here("data", "PPHS617.bib"))
```

```{r, include=FALSE}
pdf2png = function(path) {
  # only do the conversion for non-LaTeX output
  if (knitr::is_latex_output()) return(path)
  path2 = xfun::with_ext(path, "png")
  img = magick::image_read_pdf(path)
  magick::image_write(img, path2, format = "png")
  path2
}
```

```{r xaringan-themer, include=FALSE}
library(xaringanthemer)
style_xaringan(text_color = "#000000", header_color = "#737373", text_font_size = "24px",  text_font_family = "'Lucida Sans'", header_font_google = google_font("Source Sans Pro"), header_font_weight="lighter", title_slide_background_color =  "#ffffff", title_slide_text_color = "#000000", link_color = "#0000ee", footnote_font_size = "0.5em")
```

```{r data, echo=FALSE, include=FALSE}
library(haven)
d <- read_dta(here("data", "mkvtrial.dta"))
dc <- d %>% group_by(community, stratum, arm) %>%
  summarise(knows = sum(know), pop = n_distinct(id)) %>%
  mutate(prop = knows/pop, trt = recode(arm, `0` = "Control", `1` = "Treated"))
```

class: left, top

# .black[**CONTENTS**]

.left[
## .black[**I. COMPLIANCE**]
## .black[**II. ATTRITION**]
## .black[**III. SPILLOVERS**]
## .black[**IV. LIMITATIONS OF RCTs**]
]

---
## Potential issues with randomized evaluations


.right-column[

### Exchangeability
#### Treated and control groups are, in expectation, balanced on all measured and unmeasured covariates
#### This is extraordinarily powerful for achieving high internal validity.

### What could possible go wrong?
#### Non-compliance, attrition, spillovers, blinding (esp. in clinical trials).
]

---
class: left, bottom


.left[
## .black[**I. COMPLIANCE**]
## .white[**space**]
]



---
## Components of a program implementation
.footnote[See `r Citet(bib, "Shadish:2001aa")` and `r Citet(bib, "Friedman:2010yu")`]

.pull-left[
Several places where things can go wrong:

-   Inducing and measuring treatment delivery.

  -   Use manuals/documentation.
  -   Training implementers.
  -   Simplifying treatments (to the extent possible).  
]

.pull-right[
- Measuring and incentivizing treatment receipt.
    -   Written notes/handouts to patients describing treatment.
    -   Have recipients keep logs.
    -   Physiological measurements (if possible).  

-   Measuring and incentivizing adherence.
    -   Interviews regarding treatment-related activities
    -   Physical aids (e.g., reminder cards).
]

---
## What do we mean by non-compliance?
-   When people assigned to the treated group don't actually
    receive/take the treatment.
    -   Subjects may not show up for treatment (but not drop out of the
        study).
    -   Subjects can't get to where the treatment is delivered.

-   When people assigned to the treated group don't complete the entire
    course of treatment.
    -   Early in the trial people may be enthusiastic.
    -   Over time it may feel burdensome, hard to follow.
    -   Subjects may not use entire "dose" of treatment.

-   When people assigned to the control group receive/take the
    treatment.
    -   May already be getting the treatment (from elsewhere).
    -   Find other means (including subjects in the treated group).

---
## 100% compliance = ITT=ATT
- Perfect compliance means assignment perfectly predicts treatment.
- Assuming full compliance, the causal effect of treatment assignment $(ITT)$:
.center[
```{tikz ITT, echo=F, out.width="100%", cache=TRUE}
\begin{tikzpicture}[transform shape]
\tikzstyle{every node} = [rectangle, fill=gray!30]
\node[fill=white,text=red]  (z) at (0,0) [draw, align=center] {Randomized \\ allocation (Z)};
\node (y) at (8,0) [draw, align=center] {Measured \\ outcome (Y)};
\foreach \from/\to in {z/y}
\draw [->] (\from) -- (\to);
\foreach \from/\to in {z/y} 
\draw [->, color=red] (\from) -- (\to);
\end{tikzpicture}
```
]

- Is identical to the causal effect of the treatment $(ATT)$:
.center[
```{tikz ATT, echo=F, out.width="100%", cache=TRUE}
\begin{tikzpicture}[transform shape]
\tikzstyle{every node} = [rectangle, fill=gray!30]
\node[fill=white,text=red] (e) at (3.5,0) [draw, align=center] {Treatment \\ received (T)};
\node (z) at (0,0) [draw, align=center] {Randomized \\ allocation (Z)};
\node (y) at (8,0) [draw, align=center] {Measured \\ outcome (Y)};
\foreach \from/\to in {z/e}
\draw [->] (\from) -- (\to);
\foreach \from/\to in {e/y} 
\draw [->, color=red] (\from) -- (\to);
\end{tikzpicture}
```
]

---
## Why is non-compliance a problem?
-   Non-compliance can make the treated and control groups less
    exchangeable *with respect to the treatment*.

-   It reduces the difference in **actual** treatment receipt between
    those assigned to treatment and those assigned to control.

-   In order to estimate the impact of the program, we need a contrast
    in actual treatment received between treated and control groups.

-   If enough subjects assigned to treatment don't comply, and enough
    controls gain access to the treatment, it's impossible to assess the
    impact of the program.
    
---
## What compliance looks like:
.center[
```{tikz compliance1, echo=F, out.width="80%", cache=TRUE}
\begin{tikzpicture}[transform shape]
\tikzstyle{every node} = [rectangle, fill=gray!30]
\node (z) at (0,5) [draw, align=center] {Randomized \\ allocation (Z)};
\node (z1) at (-3,3) [draw, align=center] {Assigned \\ treatment (Z=1)};
\node (z0) at (3,3) [draw, align=center] {Assigned \\ control (Z=0)};
\node (z1t1) at (-4.5,0) [draw, align=center] {Got treatment \\ (T=1)};
\node (z1t0) at (-1.5,0) [draw, align=center] {Got control \\ (T=0)};
\node (z0t1) at (1.5,0) [draw, align=center] {Got treatment \\ (T=1)};
\node (z0t0) at (4.5,0) [draw, align=center] {Got control \\ (T=0)};
\foreach \from/\to in {z/z1,z/z0,z1/z1t1,z1/z1t0,z0/z0t1,z0/z0t0}
\draw [->] (\from) -- (\to);
\end{tikzpicture}
```
]

---
## What compliance looks like:
.center[
```{tikz compliance2, echo=F, out.width="80%", cache=TRUE, eval=F}
\begin{tikzpicture}[transform shape]
\tikzstyle{every node} = [rectangle, fill=gray!30]
\node (z) at (0,5) [draw, align=center] {Randomized \\ allocation (Z)};
\node (z1) at (-3,3) [draw, align=center] {Assigned \\ treatment (Z=1)};
\node (z0) at (3,3) [draw, align=center] {Assigned \\ control (Z=0)};
\node [circle, fill=white,text=red] (z1t1) at (-4.5,0) [draw, align=center] {Got treatment \\ (T=1)};
\node [circle] (z1t0) at (-1.5,0) [draw=red!95, thick, align=center] {Got control \\ (T=0)};
\node [circle] (z0t1) at (1.5,0) [draw=red!95, thick, align=center] {Got treatment \\ (T=1)};
\node [circle, fill=white,text=red] (z0t0) at (4.5,0) [draw, align=center] {Got control \\ (T=0)};
\foreach \from/\to in {z/z1,z/z0,z1/z1t1,z1/z1t0,z0/z0t1,z0/z0t0}
\draw [->] (\from) -- (\to);
\end{tikzpicture}
```
]

.center[
```{r, echo=F, out.width="80%"}
knitr::include_graphics(here("images", "compliance2.png"))
```
]


---
## Challenges with going beyond ITT
-   Non-compliance often leads to a dilution of the true treatment
    effect.

-   We can still estimate $ITT$, but we may really want to know about
    the effect of the treatment, not random assignment.

-   However, because compliance is likely affected by unmeasured
    factors, we have to rely on assumptions.

.center[
```{tikz beyondITT, echo=F, out.width="100%", cache=T}
\begin{tikzpicture}[transform shape]
\tikzstyle{every node} = [rectangle, fill=gray!30]
\node (e) at (3.5,0) [draw, align=center] {Treatment \\ received (T)};
\node[fill=white,text=red]  (z) at (0,0) [draw, align=center] {Randomized \\ allocation (Z)};
\node (u) at (6,-2) [draw, align=center] {Unmeasured \\ factors};
\node (y) at (8,0) [draw, align=center] {Measured \\ outcome (Y)};
\foreach \from/\to in {e/y, u/e, u/y}
\draw [->] (\from) -- (\to);
\foreach \from/\to in {z/e} 
\draw [->, color=red] (\from) -- (\to);
\end{tikzpicture}
```
]

---
## Example of RCT with perfect compliance
.left-column[
-   What's our ITT estimate?

-   With full compliance (since $Z=T$), this is also the effect of the
    treatment.
]

-   $RD=\left(200/1000\right)-\left(100/1000\right)=100/1000=10\%$

---
## Example of RCT with perfect compliance

.pull-right[  
                              |     $Y=1$   |   $Y=0$ |  $Y=1$  | $Y=0$  
  --------------------------- | ---------| ---------| ------- |------
  No. clusters                |   10    |    10     |        |
  Good HIV knowledge? (Y/N)   |  1356   |    908    |        |
  Population                  |  2076   |   2024    |        |
  Proportion                  |  65.6%  |   45.0%   | 20.6%   |1.46
] 


---
## Example of RCT with imperfect compliance

-   Now imagine 50% assigned to treatment did not comply.

-   [Assume]{style="color: red"} their rates are similar to controls.

---
## More non-compliance

-   Generally, this only worsens if individuals from the control group
    get access to the treatment (and the treatment works).

-   Imagine that another 25% of our controls get access to the
    treatment:

---
## What to do if we actually want the effect of the treatment

-   What if you really want the effect of the treatment
    $\left(T\rightarrow Y\right)$, not randomization
    $\left(Z\rightarrow Y\right)$?

-   Calculate Wald estimate (effect on treated).

-   Estimated as $ITT$ effect divided by difference in take up rates in
    treated vs. controls:[^2]

$$ATT=\dfrac{ITT}{P(T=1|Z=1)-P(T=1|Z=0)}$$

-   Important assumptions:

    -   Entire effect due to "compliers" in the treated group.

    -   No "defiers" (people who do opposite of assignment).

    -   More on this when we cover IV estimation.

---
## Wald estimate for our example

-   Our first example, (50% non-compliance among treated):

$$ATT=\dfrac{5\%}{0.50-0.00}=10\%$$

-   Our second example, (50% non-compliance among treated, 25%
    untreated):

$$ATT=\dfrac{2.5\%}{0.50-0.25}=10\%$$

-   In both cases we recover the "true" $ATT$, but depends on our
    assumptions about the non-compliers.

-   Ask yourself: Is "random" compliance credible?

---
## High rates of non-compliance

-   In many cases we are conducting an evaluation in order to find out
    something about the effect of the treatment.

-   Very high rates of non-compliance may make can make it difficult to
    say anything precise about the actual impact of the treatment on the
    treated (note the denominator for $ATT$).

-   Implications for power calculations.

-   Example: PLCO (Prostate, Lung, Colorectal and Ovarian) study:

    -   Tested impact of screening on cancer mortality.

    -   Investigators expected 90% compliance among treated and 20% of
        controls to get screening.

    -   Actual values were 86% and 52%.

    -   Means an effect 2x as large needed to reject the null.

---
## Strategies to limit non-compliance in impact evaluations

-   Reduce barriers to take up of the program.

    -   Consider how difficult it may be for participants to access
        program.

-   Create incentives to take up the program.

    -   Even small incentives/gifts can make a difference.

    -   Too large, however, and risk altering outcomes.

-   Simplify the program delivery.

    -   Staff training of intervention delivery.

    -   Try to reduce number of decisions made by implementers.

-   Include a "basic" version of the program, if possible.

    -   At least something for everyone may reduce treatment seeking by
        those assigned to control.

---
## Trying to measure compliance

-   Documenting take up of the treatment:

    -   Administrative records and monitoring data.

    -   Survey participants.

    -   Is there anywhere else that individuals could get the treatment?

    -   Non-survey techniques.

-   Try to identify "defiers":

    -   Individuals that might react perversely if offered or encouraged
        to take up a program.

    -   Could be done during baseline survey.

    -   Measuring personality characteristics, attitudes or knowledge
        about the treatment and outcomes.

    -   Example in Glennerster [@Glennerster:qf] of measuring girls'
        expectations about the impact of staying in school prior to
        random assignment.
        
---
class: left, bottom


.left[
## .black[**II. ATTRITION**]
## .white[**space**]
]

---
## What do we mean by "attrition"?

Definition of attrition

Attrition occurs when outcomes cannot be measured for some study
participants.

-   This is essentially a missing data problem.

-   Can lead to biased estimates of the treatment effect.

-   Even for ITT estimate.

-   Losses could be related to a patient's response to the treatment.

-   Compounded if the reasons and/or frequency of dropout differs
    between the treatment groups.

---
## Attrition creates selection bias

-   Attrition can create selection bias, even if compliance is 100%.

-   Results from "conditioning" on observed data (we can only analyze
    non-missing data).

-   Can create an association between treatment assignment and outcome,
    even if there is no effect of the program:
    
.center[
```{tikz attrition1, echo=F, out.width="80%", cache=T}
\begin{tikzpicture}[transform shape]
\tikzstyle{every node} = [rectangle, fill=gray!30]
\node (e) at (3.5,0) [draw, align=center] {Treatment \\ received (T)};
\node[fill=white,text=red]  (z) at (0,0) [draw, align=center] {Randomized \\ allocation (Z)};
\node (u) at (6,-2) [draw, align=center] {Measured \\ subjects};
\node (y) at (8,0) [draw, align=center] {Measured \\ outcome (Y)};
\foreach \from/\to in {e/u, y/u, z/e}
\draw [->, color=red] (\from) -- (\to);
\path[->, shorten >= 3pt, shorten <= 3pt, color=white, line width= 1pt] (y) edge [bend right] (e);
\path[->, shorten >= 3pt, shorten <= 3pt, color=white, line width= 1pt, dashed] (y) edge [bend right] (e);
\end{tikzpicture}
```
]

---
## Attrition creates selection bias

-   Attrition can create selection bias, even if compliance is 100%.

-   Results from "conditioning" on observed data (we can only analyze
    non-missing data).

-   Can create an association between treatment assignment and outcome,
    even if there is no effect of the program:
    
.center[
```{tikz attrition2, echo=F, out.width="80%", cache=T}
\begin{tikzpicture}[transform shape]
\tikzstyle{every node} = [rectangle, fill=gray!30]
\node (e) at (3.5,0) [draw, align=center] {Treatment \\ received (T)};
\node[fill=white,text=red]  (z) at (0,0) [draw, align=center] {Randomized \\ allocation (Z)};
\node (u) at (6,-2) [draw=red!95, thick, align=center] {Measured \\ subjects};
\node (y) at (8,0) [draw, align=center] {Measured \\ outcome (Y)};
\foreach \from/\to in {e/u, y/u, z/e}
\draw [->] (\from) -- (\to);
\path[->, shorten >= 3pt, shorten <= 3pt, color=white,line width= 1pt] (y) edge [bend right] (e);
\path[->, shorten >= 3pt, shorten <= 3pt, color=red, line width= 1pt, dashed] (y) edge [bend right] (e);
\end{tikzpicture}
```
]

---
## How does attrition data create bias?

-   Imagine a small program (n=20) to change age of smoking initiation
    ($y$).

-   Both treatment and control groups contain 2 types of people, with
    different potential outcomes:

    -   very serious students , and

    -   apathetic students .

-   We are worried about attrition/loss-to-follow up.

-   It may be that the receiving the treatment delays initiation among
    the apathetic, but being assigned to the comparison group makes them
    less likely to continue in the study (or stay in school).

-   At the end of follow-up, we only look at those still enrolled.

-   Not a fair comparison!

---
## How does attrition create bias?

-   True effect of the treatment increases initiation age by 2.5 years,
    but because of missing data we estimate that the treatment reduces
    it by 0.8 years.

Treated group (everyone is observed):
.center[
$$\begin{array}{c}
\textrm{true average}\\
\bar{y}=17.5
\end{array}\begin{cases}
\underset{20}{\frownie}\:\underset{20}{\frownie}\:\underset{20}{\frownie}\:\underset{20}{\frownie}\:\underset{20}{\frownie}\\
\underset{15}{\smiley}\:\underset{15}{\smiley}\:\underset{15}{\smiley}\:\underset{15}{\smiley}\:\underset{15}{\smiley}
\end{cases}$$
]

Comparison group (apathetic students are missing):

$$\begin{array}{c}
\textrm{true average}\\
\bar{y}=15.0
\end{array}\begin{cases}
\begin{array}{c}
\textrm{observed average}\\
\bar{y}=18.3
\end{array}\begin{cases}
\underset{20}{\frownie}\:\underset{20}{\frownie}\:\underset{20}{\frownie}\:\underset{20}{\frownie}\:\underset{20}{\frownie}\\
\underset{10}{\smiley}
\end{cases}\\
 & \underset{10}{\blacksmiley}\:\underset{10}{\blacksmiley}\:\underset{10}{\blacksmiley}\:\underset{10}{\blacksmiley}
\end{cases}$$

---
## Test



---
## Statistical inference based on quasi-likelihood

- Alternatively, we can use quasi-likelihood approaches for rates and proportions.

- Easy to implement and can directly handle binomial and Poisson response models.

- For binomial outcomes:
  - Can use binomial regression to estimate $RD$ $(\beta)$ or $RR$ $(e^{\beta})$.
  
  - If needed, can use logistic model and marginal predictions/effects to get $RD$ or $RR$.

- For rates:
  - Use Poisson with person-time as the offset to estimate rate difference and rate ratio.

---
## Example: Adolescent sexual health intervention
.footnote[See `r Citet(bib, "Ross:2007aa")`]

.pull-left[
- CRT of a school-based sexual health program in Tanzania 
  - 20 rural communities were grouped into three strata expected to have high, medium or low risk of HIV and other STIs.
  
  - 50% in each stratum received intervention.
  - A cohort of students aged 14+ followed up for 3 years to measure effects on knowledge, attitudes, reported sexual behaviour.
]

.pull-right[
                              | Treated |  Control  |  RD     | RR
  --------------------------- | ---------| ---------| ------- |------
  No. clusters                |   10    |    10     |        |
  Good HIV knowledge? (Y/N)   |  1356   |    908    |        |
  Population                  |  2076   |   2024    |        |
  Proportion                  |  65.6%  |   45.0%   | 20.6%   |1.46
]

---
## Create cluster-level summaries
.pull-left[
Individual-level data (n=4100):
```{r ti, echo=F}
di <- d %>% ungroup %>% select(community, arm, know, id)
kable(head(di), format = 'html')
```
- Variable `know` is binary.
]

.pull-right[
Cluster-level data (n=20):
```{r tc, echo=F, message=FALSE}
dct <- dc %>% mutate(prop = round(prop, 2)) %>% ungroup() %>%
  select(community, arm, knows, pop, prop)
kable(head(dct), format='html')
```
- Variable `prop` is a proportion (knows / pop).
]

---
## Unpaired t-test of cluster-level outcomes
.left-column[
- Simple plot of each cluster mean and average (+/-SE) by treatment arm.
]

.right-column[
.center[
```{r plot1, echo=FALSE, message=FALSE, fig.dim=c(8, 6)}
ggplot(dc, aes(x=trt, y=prop)) + geom_point() + stat_summary(color="red", size=1) + xlab("Study arm") + ylab("Proportion good HIV knowledge") + theme_bw() + theme(text = element_text(size=24))
```
]]

---
## Unpaired t-test of cluster-level outcomes
.footnote[Stata calculates the RD and 95% CI for the un-paired t-test using the `ttest prop, by(arm)` command.]

.pull-left[
- Cluster-level rates can be considered as two independent random
samples.

- In R it's simple to use the `t.test()` function to test whether means differ between arms
]

.pull-right[
```{r ttest}
t.test(prop ~ trt, data=dc)
```
]

---
## Risk ratio using Poisson on clusters
- Poisson regression with population as offset gives the risk ratio.

- Variance of RR is underestimated since between-cluster variablility (also called overdispersion) is not accounted for.

- We can multiply the SE by a scale parameter (Pearson's $\chi^{2}$=df ) to
account for overdispersion or use 'quasipoisson' family:

`glm(knows ~ arm, offset=log(pop), data=dc, family="quasipoisson")`
```{r poisson, echo=F}
poi <- glm(knows ~ arm, offset=log(pop), data=dc, family="quasipoisson")
dust(poi, conf.int=TRUE) %>%
  sprinkle(col = c(2:4, 6:7), round = 2) %>%
  sprinkle(col = 5, fn = quote(pval_string(value))) %>%
  sprinkle_colnames(term = "Parameter", 
                    estimate = "Estimate",
                    std.error = "SE",
                    statistic = "t-Stat",
                    p.value = "p-value",
                    conf.low = "95% LL",
                    conf.high = "95% UL") %>%
  kable() %>%
  kable_styling()
```
- Poisson coefficient $(\beta)$ = 0.38, so $exp(\beta)$=1.46, and we say the proportion with good HIV knowledge is 46% higher for communities randomized to treatment.

---
## Translating back to the absolute scale
.footnote[See the `margins` package in R and similar command in Stata]

.pull-left[
- Under our Poisson model, we can generate predicted counterfactual estimates for the whole population under treatment or under control.

- These are **marginal** risks

Group  | Risk | 95% CI  
-------| ----------| -----------------  
Control |      0.45 | [0.40, 0.50]  
Treated |      0.65 | [0.59, 0.72] 
Difference | 0.20 | [0.12, 0.29]

]

.pull-right[
```{r mp, echo=F, message=FALSE, warning=FALSE, results='hide'}
poit <- glm(knows ~ trt, offset=log(pop), data=dc, family="quasipoisson")
mp <- ggpredict(poit, terms=c("trt", "pop [1]"))
p <- plot(mp)
p + theme(text = element_text(size=24)) + 
  labs(x = "Study arm", y = "Proportion", 
       title = "Predicted % good HIV knowledge")
```
]

---
## CRTs: analysis using individual-level data

-  For small numbers of clusters, most robust analysis is to use cluster-level summaries.

-  For larger clusters (e.g, >15 *clusters* per treatment arm), using individual-level data may increase efficiency.

- Also possible to evaluate sub-group effects, allow for effect measure modification.

- Need to account statistically for clustering of individuals:
  - If not, standard errors will be underestimated. 
  
  - Risk of inferring precise treatment effect when true evidence is to the contrary.  
  

---
.footnote[`r Citet(bib, "Merlo:2005aa")`]

.left-column[
Sources of variation in cluster RCTs
]

.right.column[
.center[
```{r, echo=F, out.width="80%"}
knitr::include_graphics(here("images", "merlo-fig.png"))
```
]]

---
## Simple random effects model
- General form of random effects (RE) model:

 $$y_{ij}=\alpha+\left(u_{j}+e_{ij}\right)$$

- $u_{j}$ is a cluster-level random effect; $e_{ij}$ is an individual-level error term. 

- $\left(u_{j}+e_{ij}\right)$ is a compound error term that accounts for between- and within-cluster variation.

- No covariates (or treatment) so this is basically a variance decomposition model.

- Can tell us how much of the overall variance is between clusters (ICC).

---
## Implementation of RE model
- In R you can use the `lme4` package for linear and non-linear random effects models, e.g.:

`glmer(know ~ (1 | community), family = "poisson", data = d)`

which gives the following output for the "fixed" part of the model:

```{r re1, echo=F, error=FALSE}
m0 <- glmer(know ~ (1 | community), family = "poisson", data = d) 
dust(m0, effects="fixed", conf.int=TRUE) %>%
  sprinkle(col = c(3:5, 7:8), round = 2) %>%
  sprinkle(col = 6, fn = quote(pval_string(value))) %>%
  sprinkle_colnames(effect = "Effect",
                    term = "Parameter",
                    estimate = "Estimate",
                    std.error = "SE",
                    statistic = "t-Stat",
                    p.value = "p-value",
                    conf.low = "95% LL",
                    conf.high = "95% UL") %>%
  kable() %>%
  kable_styling() 
```

- Note that the intercept here is the "grand mean" proportion `know` for the whole population $(exp^{-0.62}=54\%)$. 

- Not a simple mean, as the RE model "shrinks" estimates from smaller clusters toward the overall mean.

---
## Variance partitioning

- Multi-level models also provide estimates of variance parameters, i.e., how much variation is between clusters.

- The "random" part of the model summary also provides an estimate of the cluster-level variance:

Groups |   Name    |    Variance | Std.Dev.
-------|-----------|-------------|--------
community | (Intercept) | 0.05289  |  0.23 

- You can use the estimated variance to calculate the ICC. 

- For a binary outcome, this is calculated as $\sigma^2_{B} / (\sigma^2_{B} + \pi^2/3)$, which in this case is $0.05 / (0.05 + \pi^2/3) = 0.016$
- We would say that 1.6% of the total variation in HIV knowledge is between communities.

---
# How to deal with clustering
- Use OLS or GLM models with clustered standard errors.

  - In Stata specified using the `vce(cluster clustervarname)` option.
  
  - In R you can use the `clubsandwich` or `sandwich` packages (or others, Google is your friend).

- Use mixed/hierarchical models:
  1. Random effects (RE) models (cluster-specific).
  
  2. Generalized estimating equations (GEE) (marginal).
  - Note that 1 and 2 have different interpretations.
  

---
## Random effects models for treatment effect
- General form of random effects model for treatment (without any additional baseline covariates):

$$y_{ij}=\alpha+\beta_{j}Z_{j}+\left(u_{j}+e_{ij}\right)$$

- $\beta_{j}$ captures the effect of being in the treated $\left(Z=1\right)$ vs. control $(Z=0)$ group.

- $u_{j}$ is a cluster-level random effect; $e_{ij}$ is an individual-level error term. 

- $\left(u_{j}+e_{ij}\right)$ is a compound error term that accounts for between- and within-cluster variation.

---
## Adding the treatment to our model
- Let's add the treatment arm variable to our model.

`glmer(know ~ arm + (1 | community), family = "poisson", data = d)`

which gives the following output for the "fixed" part of the model:

```{r re2, echo=F}
m1 <- glmer(know ~ arm + (1 | community), family = "poisson", data = d) 
dust(m1, effects="fixed", conf.int=TRUE) %>%
  sprinkle(col = c(3:5, 7:8), round = 2) %>%
  sprinkle(col = 6, fn = quote(pval_string(value))) %>%
  sprinkle_colnames(effect = "Effect",
                    term = "Parameter",
                    estimate = "Estimate",
                    std.error = "SE",
                    statistic = "t-Stat",
                    p.value = "p-value",
                    conf.low = "95% LL",
                    conf.high = "95% UL") %>%
  kable() %>%
  kable_styling() 
```

- Note that our coefficient on `arm` is $\beta=0.38$, exactly what we estimated using the cluster-level summaries, corresponding to an $RR$ of $e^{\beta}=1.46$.

---
# Model based estimates
.pull-left[
- Important to remember that clustering creates a need to account for non-independence among observations within clusters.

- Ignoring this will lead to *underestimates* of random error.

- Confidence intervals will be too narrow.
]

.pull-right[
- Compare the SE on `arm` from a naive model that ignores clustering to a model that uses either cluster robust SEs or our RE model:

Clustering  | $\beta$ | SE $(\beta)$
-------| ----------| -----------------  
Ignored |      0.38 | 0.043
Clustered SEs |      0.38 |0.076
RE model | 0.38| 0.072
]

---
# Adjustment for covariates
- General form of random effects model (with covariates):

$$y_{ij}=\alpha+\beta_{j}Z_{j}+\sum_{k=1}^{K}\gamma_{k}C_{ijk}+\left(u_{j}+e_{ij}\right)$$

- Now our model includes parameters for each of $C_{k}$ continuous or categorical covariates.

- Interpretation is no different than for any other multivariable model.

- As noted before, covariates should be specified in advance.

---
## Adding covariates to our example
.pull-left[
- Let's add covariates for ethnic group and stratum to our model.

- Small impact on the point estimate for `arm`, and small reductions in the SE (greater precision).

- Not surprising this doesn't affect $\beta_{arm}$ since groups are exchangeable at baseline.
]

.pull-right[

  | $\beta$ | SE $(\beta)$  |  | $\beta$  | SE $(\beta)$  
-------| ----------| -----------------  
Treated arm     | 0.38 | 0.072 | | 0.37  | 0.064
**Ethnic group**|      |       | |       | 
Sukuma      |      |       | | -0.14 | 0.05
**Stratum**     |      |       | |       |
stratum 2       |      |       | |  0.03 | 0.08   
stratum 3        |      |       | |  0.05 | 0.08
]

---
class: left, bottom


.left[
## .black[**III. OTHER ISSUES**]
## .white[**space**]
]

---
## Multiple testing: What's the problem?
- Investigators often specify a small set of measures to serve as the primary outcomes, with another (often larger) set listed as secondary.

- What is the problem?
- Type I error typically set at a = 0.05.

- If many hypotheses are tested, the .red[“combined” Type 1 error] rate could be considerably larger.
- E.g., if the null is actually true, the chances of at least 1 spurious finding are:
  - 64% percent if 20 tests are conducted;
  
  - 92% percent for 50 tests.

---
## Multiple testing: What's should you do?
.pull-left[
- What should you do about multiple testing?

- Best way is to avoid it: be specific and concise in defining outcomes!

- May not be entirely feasible given the substantial up-front investment.

- Potentially too conservative?

]

.pull-right[
### CONSORT 2010: 
>having several primary outcomes, however, incurs the problems of interpretation associated with multiplicity of analyses...and is not recommended.
]


---
# Multiple testing: What's should you do?
.left-column[
```{r, echo=F, out.height="100%", out.width="100%"}
ggplot() + geom_fontawesome("fa-clipboard", color='#f5bc6c') + theme_void()
```
]
.right-column[
- Others provide somewhat more guidance `r Citet(bib, "Schochet:2008gf")`.

  - specify primary, secondary, and exploratory analyses in your protocol.
  
  - specify subgroup analyses in advance.
  - conducting hypothesis tests on (pre-specified) composite outcomes.

- Applying multiplicity correction procedures to composites across domains.
]

---
# Subgroup analysis
.pull-left[
- Famous example in Lancet trial of aspirin vs placebo in acute
myocardial infarction.

- Aspirin was ineffective in patients born under the star signs of Libra
and Gemini (150 deaths on aspirin vs 147 on placebo, p=0.5), but
was beneficial in the remainder (654 deaths on aspirin vs 869 on
placebo, p<0.0001).

- Do you believe it?
]

.pull-right[
```{r isis, echo=F, out.width="100%"}
knitr::include_graphics(here("images", "isis-title.png"))
```
]

---
.footnote[See `r Citet(bib, "Rothwell:2005kq")` ]
.left-column[
- Rothwell (2005) gives several examples of subgroup analyses later demonstrated to be invalid.
]

.right-column[
.center[
```{r, echo=F, out.width="100%"}
knitr::include_graphics(here("images", "rothwell-t1.png"))
```
]]

---
## Subgroup analyses
- Asks the basic question: “Are the intervention effects the same across levels of important baseline factors?”

- Groups are often of substantive or policy interest.
- However, need to consider the multiple testing problem.
- Concerns about post-hoc “discoveries” not disclosed as post-hoc.

- How to conduct subgroup analyses:
  - Consider adjusting for multiple comparisons.
  - Subgroups should be pre-specified.
  - Should be assessed using interaction tests (rather than by within group estimates of the treatment effect)

---
##  Model-based estimation for subgroup analyses
- Subgroup analyses may generally be implemented with straightforward extensions of models for average effects.

- Essentially including interaction terms between treatment and subgroup of interest. 

- For our random effects model, we can add subgroup $G$:

$$y_{ij}=\alpha+\beta_{j}Z_{j}+\gamma_{ij}G_{ij}+\delta_{ij}\left({\color{red}Z_{j}}*G_{ij}\right)+\left(u_{j}+e_{ij}\right)$$

- where now $\gamma$ is the effect of being in group $G$ when $Z=0$.

- $\delta$ provides an estimate of any departure from exact additivity of joint exposure to both $Z$ and $G$.

---
# Attrition
.pull-left[
### Concerns about attrition
- What if actually receiving the treatment improves outcomes among “healthy” subtypes, but being assigned to the comparison group makes them less likely to continue in the study?

- At the end of follow-up, we only look at those still enrolled.

- Not a fair comparison = bias!
]

--

.pull-right[
### What to do?
- Determine overall rate of attrition.

- Attempt to measure whether attrition was differential between treated and control groups.

- Conduct sensitivity analysis for your main analysis.
]

---
### References

```{r, results='asis', echo=FALSE}
#PrintBibliography(bib, start=1, stop=5)
print_bib_rmd(bib, start=1, stop=5)
```

---
### References (cont)
```{r, results='asis', echo=FALSE, warning=FALSE}
print_bib_rmd(bib, start=6, stop=10)
```
